[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Visual Statistical Analysis",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting.\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Visual Statistical Analysis",
    "section": "Visualizing the uncertainty of point estimates",
    "text": "Visualizing the uncertainty of point estimates\n\nA point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\nImportant:\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nNote: For the mathematical explanation, please refer to Slide 20 of Lesson 4.\nNext, the code chunk below will\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by race\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-ggdist-package",
    "title": "Visual Statistical Analysis",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Visual Statistical Analysis",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Visual Statistical Analysis",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Visual Statistical Analysis",
    "section": "Overview",
    "text": "Overview\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages",
    "title": "Visual Statistical Analysis",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data-1",
    "title": "Visual Statistical Analysis",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "title": "Visual Statistical Analysis",
    "section": "FunnelPlotR methods",
    "text": "FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion.\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05)   \n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers. Plot is adjusted for overdispersion.\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", \n  y_label = \"Cumulative Fatality Rate\"  \n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.\nPlot is adjusted for overdispersion.\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Visual Statistical Analysis",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "title": "Visual Statistical Analysis",
    "section": "References",
    "text": "References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-ggplot2-and-ggiraph-codes",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-ggplot2-and-ggiraph-codes",
    "title": "Interactivity in R",
    "section": "Comparing ggplot2 and ggiraph codes",
    "text": "Comparing ggplot2 and ggiraph codes\nThe original ggplot2 code chunk.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5, \n               dotsize = 0.5) +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\n\n\n\n\nThe ggiraph code chunk.\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#displaying-multiple-information-on-tooltip",
    "title": "Interactivity in R",
    "section": "Displaying multiple information on tooltip",
    "text": "Displaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\ntooltip_css <- \"background-color:white; \nfont-style:bold; color:turquoise;\"\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(opts_tooltip(css = tooltip_css)))  \n\n\n\n\n\n\nDisplaying statistics on tooltip\n\ntooltip <- function(y, ymax, accuracy = 0.01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean Math Scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\nHover effect with data_id aesthetic\nCode chunk below show the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #<<\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),             \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on ther web.\nThe code chunk below shown an example of onclick.\n\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click. Note that click actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#coordinated-multiple-views-with-ggiraph",
    "title": "Interactivity in R",
    "section": "Coordinated Multiple Views with ggiraph",
    "text": "Coordinated Multiple Views with ggiraph\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #<<\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-plot_ly-method",
    "title": "Interactivity in R",
    "section": "Creating an interactive scatter plot: plot_ly() method",
    "text": "Creating an interactive scatter plot: plot_ly() method\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) \n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nChanging colour pallete: plot_ly() method\nIn the code chunk below, colors argument is used to change the default colour palette to ColorBrewel colour palette.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\") #<<\n\n\n\n\n\n\n\nCustomising colour scheme: plot_ly() method\nIn the code chunk below, a customised colour scheme is created. Then, colors argument is used to change the default colour palette to the customised colour scheme. Interactive: Click on the colour symbol at the legend.\n\npal <- c(\"red\", \"purple\", \"blue\", \"green\") \n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = pal) \n\n\n\n\n\n\n\nCustomising tooltip: plot_ly() method\nIn the code chunk below, text argument is used to change the default tooltip. Interactive: click on the colour symbol at the legend.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     \n                      \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\")\n\n\n\n\n\n\n\nWorking with layout: plot_ly() method\nIn the code chunk below, layout argument is used to change the default tooltip. Interactive:\n\nClick on the colour symbol at the legend.\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     \n                      \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\") %>%\n  layout(title = 'English Score versus Maths Score ', \n         xaxis = list(range = c(0, 100)),             \n         yaxis = list(range = c(0, 100)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "Interactivity in R",
    "section": "Creating an interactive scatter plot: ggplotly() method",
    "text": "Creating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly(). Notice that the only extra line you need to include in the code chunk is ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) \n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nCode chunk below plots two scatterplots and places them next to each other side-by-side by using subplot() of plotly package.\n\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),            \n        ggplotly(p2))            \n\n\n\n\n\nNotice that these two scatter plots are not linked.\n\n\nCoordinated Multiple Views with plotly\nTo create a coordinated scatterplots, highlight_key() of plotly package is used.\n\nd <- highlight_key(exam_data)  \np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Interactivity in R",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Interactivity in R",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nGetting started\nAdd the following packages in the packages list:\n\ngganimate: An ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\n\n\npacman::p_load(gifski, gapminder, readxl) \n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      \"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-large-data-interactively",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-large-data-interactively",
    "title": "Interactivity in R",
    "section": "Visualising Large Data Interactively",
    "text": "Visualising Large Data Interactively\nIn this hands-on exercise you will learn how to visualise large data by using packed bar methods. For the purpose of this hands-on exercise, two data sets will be used. They are:\n\nGDP.csv provides GDP, GDP per capita and GDP PPP data for world countries from 2000 to 2020. The data was extracted from World Development Indicators Database of World Bank.\nWorldCountry.csv provides a list of country names and the continent they belong to extracted from Statistics Times.\nWrite a code chunk to import both data sets by using read_csv() of readr package.\n\nThe solution:\n\nGDP <- read_csv(\"data/GDP.csv\")\n\nWorldCountry <- read_csv(\"data/WorldCountry.csv\")\n\n\nData preparetion\nBefore programming the data visualisation, it is important for us to reshape, wrangle and transform the raw data to meet the data visualisation need.\nCode chunk below performs following tasks:\n\nmutate() of dplyr package is used to convert all values in the 202 field into numeric data type.\nselect() of dplyr package is used to extract column 1 to 3 and Values field.\npivot_wider() of tidyr package is used to split the values in Series Name field into columns.\nleft_join() of dplyr package is used to perform a left-join by using Country Code of GDP_selected and ISO-alpha3 Code of WorldCountry tibble data tables as unique identifier.\n\n\nGDP_selected <- GDP %>%\n  mutate(Values = as.numeric(`2020`)) %>%\n  select(1:3, Values) %>%\n  pivot_wider(names_from = `Series Name`,\n              values_from = `Values`) %>%\n  left_join(y=WorldCountry, by = c(\"Country Code\" = \"ISO-alpha3 Code\"))\n\n\n\nIntroducing packed bar method\n\npacked bar is a relatively new data visualisation method introduced by Xan Gregg from JMP.\n\nIt aims to support the need of visualising skewed data over hundreds of categories.\n\nThe idea is to support the Focus+Context data visualization principle.\nVisit this JMP Blog to learn more about the design principles of packed bar.\n\n\n\nData Preparation\nAs usual, we need to prepare the data before building the packed bar. Prepare the data by using the code chunk below.\n\nGDP_selected <- GDP %>%\n  mutate(GDP = as.numeric(`2020`)) %>%\n  filter(`Series Name` == \"GDP (current US$)\") %>%\n  select(1:2, GDP) %>%\n  na.omit()\n\n\n\nThing to learn from the code chunk above\n\nna.omit() is used to exclude rows with missing values. This is because rPackedBar package does not support missing values.\n\n\n\n\nBuilding a packed bar by using rPackedBar package.\n\npacman::p_load(rPackedBar) \n\nIn the code chunk below, plotly_packed_bar() of rPackedBar package is used to create an interactive packed bar.\n\np = plotly_packed_bar(\n  input_data = GDP_selected,\n  label_column = \"Country Name\",\n  value_column = \"GDP\",\n  number_rows = 10,\n  plot_title = \"Top 10 countries by GDP, 2020\",\n  xaxis_label = \"GDP (US$)\",\n  hover_label = \"GDP\",\n  min_label_width = 0.018,\n  color_bar_color = \"#00aced\",\n  label_color = \"white\")\nplotly::config(p, displayModeBar = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Interactivity in R",
    "section": "Reference",
    "text": "Reference\n\nggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\n\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\nplotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels\n\n\n\nPacked Bar\nrPackedBar: Packed Bar Charts with ‘plotly’\n\nVisualizing Twitter Data with a Packed Barchart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "exam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data = exam_data, \n       aes(x = MATHS,\n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(model = lm, size = 0.5) +\n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in geom_smooth(model = lm, size = 0.5): Ignoring unknown parameters:\n`model`\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, \n              base_size = 15, \n              grid = \"Y\") \n\n\n\n\n\n#create composite plot by combining multiple graphs.\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\np1 + p2 / p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# working with patchwork\n\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Learnings from R.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Learnings from R.html",
    "title": "ggplot learnings",
    "section": "",
    "text": "dd + theme(legend.position = “bottom”)\ndownload gridExtra package to change legend size\ndd + theme(legend.key.size = unit(5, “mm”), legend.key = element_rect(fill = “white”))\nhttps://www3.nd.edu/~steve/computing_with_data/12_Scales_themes/scales_themes.html\nchanging axis details:\ndd + theme(axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),\naxis.text = element_text(size = 16))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-data",
    "title": "Building Ternary Plot with R",
    "section": "The data",
    "text": "The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\nImporting Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data",
    "title": "Building Ternary Plot with R",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-static-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-static-ternary-diagram",
    "title": "Building Ternary Plot with R",
    "section": "Plotting a static ternary diagram",
    "text": "Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-an-interative-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-an-interative-ternary-diagram",
    "title": "Building Ternary Plot with R",
    "section": "Plotting an interative ternary diagram",
    "text": "Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-data",
    "title": "Building Ternary Plot with R",
    "section": "Importing Data",
    "text": "Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-a-basic-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-a-basic-correlation-matrix",
    "title": "Building Ternary Plot with R",
    "section": "Building a basic correlation matrix",
    "text": "Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#drawing-the-lower-corner",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#drawing-the-lower-corner",
    "title": "Building Ternary Plot with R",
    "section": "Drawing the lower corner",
    "text": "Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chunk below.\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#including-with-correlation-coefficients",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#including-with-correlation-coefficients",
    "title": "Building Ternary Plot with R",
    "section": "Including with correlation coefficients",
    "text": "Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-basic-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-basic-plot",
    "title": "Building Ternary Plot with R",
    "section": "The basic plot",
    "text": "The basic plot\nOne of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n# ggstatsplot::ggcorrmat(\n#   data = wine,\n#   cor.vars = 1:11)\n\n\n# ggstatsplot::ggcorrmat(\n#   data = wine,\n#   cor.vars = 1:11,\n#   ggcorrplot.args = list(outline.color = \"black\",\n#                          hc.order = TRUE,\n#                          tl.cex = 10),\n#   title    = \"Correlogram for wine dataset\",\n#   subtitle = \"Four pairs are no significant at p < 0.05\"\n# )\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-multiple-plots",
    "title": "Building Ternary Plot with R",
    "section": "Building multiple plots",
    "text": "Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Building Ternary Plot with R",
    "section": "Visualising Correlation Matrix using corrplot Package",
    "text": "Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started-with-corrplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started-with-corrplot",
    "title": "Building Ternary Plot with R",
    "section": "Getting started with corrplot",
    "text": "Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-visual-geometrics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-visual-geometrics",
    "title": "Building Ternary Plot with R",
    "section": "Working with visual geometrics",
    "text": "Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\nWorking with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\nWorking with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#combining-corrgram-with-the-significant-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#combining-corrgram-with-the-significant-test",
    "title": "Building Ternary Plot with R",
    "section": "Combining corrgram with the significant test",
    "text": "Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reorder-a-corrgram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#reorder-a-corrgram",
    "title": "Building Ternary Plot with R",
    "section": "Reorder a corrgram",
    "text": "Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#r-packages",
    "title": "Building Ternary Plot with R",
    "section": "R packages",
    "text": "R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-data-set",
    "title": "Building Ternary Plot with R",
    "section": "Importing the data set",
    "text": "Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#preparing-the-data-1",
    "title": "Building Ternary Plot with R",
    "section": "Preparing the data",
    "text": "Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) <- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#transforming-the-data-frame-into-a-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#transforming-the-data-frame-into-a-matrix",
    "title": "Building Ternary Plot with R",
    "section": "Transforming the data frame into a matrix",
    "text": "Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#heatmap-of-r-stats",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#heatmap-of-r-stats",
    "title": "Building Ternary Plot with R",
    "section": "heatmap() of R Stats",
    "text": "heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-heatmaply",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-heatmaply",
    "title": "Building Ternary Plot with R",
    "section": "Working with heatmaply",
    "text": "Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-trasformation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-trasformation",
    "title": "Building Ternary Plot with R",
    "section": "Data trasformation",
    "text": "Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\n\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nPercentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#clustering-algorithm",
    "title": "Building Ternary Plot with R",
    "section": "Clustering algorithm",
    "text": "Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#seriation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#seriation",
    "title": "Building Ternary Plot with R",
    "section": "5.4 Seriation",
    "text": "5.4 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-colour-palettes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#working-with-colour-palettes",
    "title": "Building Ternary Plot with R",
    "section": "Working with colour palettes",
    "text": "Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-finishing-touch",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#the-finishing-touch",
    "title": "Building Ternary Plot with R",
    "section": "The finishing touch",
    "text": "The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-3",
    "title": "Building Ternary Plot with R",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "title": "Building Ternary Plot with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-simple-parallel-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-simple-parallel-coordinates",
    "title": "Building Ternary Plot with R",
    "section": "Plotting a simple parallel coordinates",
    "text": "Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Building Ternary Plot with R",
    "section": "Plotting a parallel coordinates with boxplot",
    "text": "Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\n\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#parallel-coordinates-with-facet",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#parallel-coordinates-with-facet",
    "title": "Building Ternary Plot with R",
    "section": "Parallel coordinates with facet",
    "text": "Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#rotating-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#rotating-x-axis-text-label",
    "title": "Building Ternary Plot with R",
    "section": "Rotating x-axis text label",
    "text": "Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adjusting-the-rotated-x-axis-text-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#adjusting-the-rotated-x-axis-text-label",
    "title": "Building Ternary Plot with R",
    "section": "Adjusting the rotated x-axis text label",
    "text": "Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#rotate-axis-label",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#rotate-axis-label",
    "title": "Building Ternary Plot with R",
    "section": "Rotate axis label",
    "text": "Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#changing-the-colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#changing-the-colour-scheme",
    "title": "Building Ternary Plot with R",
    "section": "Changing the colour scheme",
    "text": "Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#parallel-coordinates-plot-with-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#parallel-coordinates-plot-with-histogram",
    "title": "Building Ternary Plot with R",
    "section": "Parallel coordinates plot with histogram",
    "text": "Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\nReferences\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Network Data Visualisation and Analysis",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\nIn this step, you will import GAStech_email_node.csv and GAStech_email_edges.csv into RStudio environment by using read_csv() of readr package.\n\n\nCode\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nNext, we will examine the structure of the data frame using glimpse() of dplyr.\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nWarning: The output report of GAStech_edges above reveals that the SentDate is treated as “Character”” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\nThe code chunk below will be used to perform the changes.\n\n\nCode\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nThings to learn from the code chunk above:\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\n\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\nRows: 9,063\nColumns: 10\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    <date> 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     <ord> Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\n\nCode\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\nThings to learn from the code chunk above:\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\nRows: 1,372\nColumns: 4\n$ source  <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  <dbl> 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday <ord> Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  <int> 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\nIn this section, you will learn how to create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nBefore getting started, you are advised to read these two articles:\n\nIntroducing tidygraph\ntidygraph 1.1 – A tidy hope\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network.\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n\nIn this section, you will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\n\nCode\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\n\nCode\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# … with 1,369 more rows\n\n\n\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nCode\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# … with 1,366 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\n[edges]((https://cran.r-project.org/web/packages/ggraph/vignettes/Edges.html) and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\n\nCode\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\n\nCode\ng <- ggraph(GAStech_graph,\n            layout = \"fr\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\n\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\n\nCode\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\nggraph() support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\n\nCode\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\n\nCode\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\n\nCode\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nCode\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\nThe code chunk below uses theme() to change the position of the legend.\n\n\nCode\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\n\nCode\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable for you to read it’s reference guide at least once.\n\n\nCode\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nCode\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nCode\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nCode\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\nBefore we can plot the interactive network graph, we need to prepare the data model by using the code chunk below.\n\n\nCode\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nCode\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nCode\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument. ]\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n- The argument highlightNearest highlights nearest when clicking a node.\n- The argument nodesIdSelection adds an id node selection creating an HTML select element.\nShow the codeSelect by idMat.BramarAnda.RiberaRachel.PantanalLinda.LagosRuscella.Mies.HaberCarla.ForluniauCornelia.LaisKanon.HerreroVarja.LagosStenig.FusilMarin.OndaAxel.CalzasBrand.TempestadElsa.OrillaIsande.BorrascaKare.OrillaFelix.BalasLars.AzadaLidelse.DedosWillem.Vasco-PaisBertrand.OvanAdra.NubarronBirgitta.FrenteGustav.CazarVira.FrenteLinnea.BergenLucas.AlcazarIsak.BazaNils.CalixtoSven.FlechaEmile.ArpaVarro.AwelonDante.CoginianEdvard.VannHennie.OsvaldoIsia.VannMinke.MiesSten.Sanjorge.JrFelix.ResumirHideki.CocinaroInga.FerroLoreto.BodrogiIngrid.BarrancoAda.Campo-CorrenteOrhan.StrumAdan.MorlunAlbina.HafonBenito.HawelonCecilia.MorluniauClaudio.HawelonDylan.ScozzeseHenk.MiesIrene.NantValeria.Morlun\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Visualising Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Visualising Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n\n\nCode\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, CGPfunctions, readxl, knitr,data.table, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Visualising Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "title": "Visualising Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Visualising Time-oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting started, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice <- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Data: Rice\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-horizon-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-horizon-plot",
    "title": "Visualising Time-oriented Data",
    "section": "Plotting Horizon Plot",
    "text": "Plotting Horizon Plot\nIn this section, you will learn how to plot a horizon graph by using ggHoriPlot package.\nBefore getting start, make sure that ggHoriPlot has been included in the pacman::p_load(...) statement above. Then, refer to Getting Started to learn more about the function. Lastly, read [geom_horizon()](https://rivasiker.github.io/ggHoriPlot/reference/geom_horizon.html to learn more about the usage ot its arguments.\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`))\n\n\nStep 2: Plotting the horizon graph\nNext, the code chunk below will be used to plot the horizon graph.\n\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Introdution to R",
    "section": "",
    "text": "Plotting a simple bar chart\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Educational Background\n\nMaster of Information Technology in Business (Analytics track) - Singapore Management University (Singapore): This was a really intensive data analytics course with a balance of theoretical and practical knowledge. The courses covered were Python Programming, Statistics, Data Analytics Lab, Customer Analytics, Applied Machine Learning, Visual Analytics, Social Analytics and Big Data.\nMaster in Economics - Narsee Monjee Institute of Management Studies (Mumbai, India): I majored in Economics and thought my course I have an advanced understanding of macro-economic, micro-economic and econometric concepts!\nBachelor in Commerce - HR College (Mumbai, India): My bachelor’s set the foundation of accounting and finance. \n\n\n\nWork Experience\n\nData Analytics Intern - Mighty Jaxx: I have leveraged my technical and analytical skills to design and test data engineering infrastructure, enable competitor analysis through web-scraping in Python, and visualized imperative data points using Tableau for the senior management.\nInvestment Performance Specialist - JP Morgan: I have managed and analysed large Assets under management databases, automated periodic reports in Alteryx to minimise manual errors and strengthen audit controls to save significant amounts of time and resources for my previous employers.\n\n\n\nLearnings and Skills\n\nUnderstanding of Data: the ability to comprehend and manipulate large datasets using programming languages (Python, R, SQL). Additionally, tidy and pre-process the data to remove errors, inconsistencies to render it complete for analysis.\nData Analysis and Visualisation: the knowledge to use the right statistical methods to meaningfully analyze the data and extract insights. Also, create visualizations (Tableau, R, Python, Power BI) that help to communicate complex data insights to stakeholders.\nTime management: my corporate experience and academic workload have instilled within me an ability to multi-task. I can prioritise important tasks and manage my time effectively to meet my deadlines and deliver results.\nLeadership and Collaboration: At JP Morgan, I had the opportunity to lead a team of five people for automating manual processes. I think I succeeded as a leader because I was able to delegate tasks, ensure my team met the deadline andeveryone worked harmoniously. I can also work effectively in a team environment and collaborate with other analysts, data scientists, and stakeholders.\n\n\n\nMiscellaneous Information\n\nI am fluent in English and Hindi\nI am an expat and will be requiring an employment pass to work in Singapore\nPhone number: +65 88233779\nEmail: aishwarya.2021@mitb.smu.edu.sg | aishwarya@maloo.in"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Age-Population Pyramid - Singapore 2022 (Tableau)",
    "section": "",
    "text": "The task is to create a trellis display chart, using Tableau, showcasing the age and gender demographic information of Singapore’s population in any nine planning areas of choice. The data used to carry out this visualization is ’Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022’ taken from the Department of Statistics, Singapore. A detailed account of the steps and procedures for the visualisation needs to be documented along with an analysis of the observations from the visualisation created."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-processing",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-processing",
    "title": "Age-Population Pyramid - Singapore 2022 (Tableau)",
    "section": "3.1 Data Processing",
    "text": "3.1 Data Processing\n\nDownloading the dataset: From the main dataset downloaded, the datasets extracted for our age-sex pyramid are, ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas.’\n\nData Cleaning: The data was cleaned for both ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas’ in MS Excel. The’Planning Area’ sections by ‘Age’ were combined. The cleaning process entailed removing the the ‘Total’ columns using ‘command + -’. Additionally, the empty cells between each planning area were filled such that each subzone had a corresponding planning area alongside.\n\nPivoting the worksheets in Tableau: It is desirable to have data structured as long and lean for better analysis in Tableau. Hence, the short and wide data structure in MS Excel worksheets was opened in Tableau, and all the five-year age bands were pivoted to the long and lean data structure. This process is done for both the male and female worksheets.\na) Load the ‘Population of Males by Age Groups and Planning Areas’ saved as ‘Male Population’ and ‘Population of Females by Age Groups and Planning Areas’ saved as ‘Female Population’ onto Tableau separately. To load the datasets, go to ‘Microsoft Excel’ and click on the desired file.\n\nb) In ‘Data Source’, select all the age groups from ‘0-4’ to ‘85 & Over’ using the ‘shift’ key and then go to drop down arrow next to ‘Abc’ under any of the age groups and select ‘Pivot’.\n\nc) Go to ‘Data’ and select ‘Export Data to csv’, ensure that this process is completed for both the ‘Male population’ and ‘Female population’.\n\nd) The column names retained in each MS Excel worksheets post pivoting were ‘Planning Area’, ‘Subzone’, ‘Age’ (for five-year age bands), ‘Gender’ (Male or Female, depending on the data worksheet), and ‘Population’ (population count). Additionally, add another column and call it ‘Gender’ and put ‘Male’ and ‘Female’ according to the worksheet required.\n\ne) Then combine these workbooks as separate sheets in another workbook, saved as ‘SG Population by Subzone’\n\n3.2 Preparing the Tableau Dashboard\n3.2.1 Union of the Male and Female Population datasets\n\nRelaunch Tableau and load the newly created MS Excel workbook ‘SG Population by Subzone’ which will display the ‘Male Population’ and the ‘Female Population’ sheets. Click on ‘New Union’ and in the dialog box that appears, drag the two sheets therein and click ‘OK’.\n\n\n3.2.2 Creating 3X3 Panel Chart\n\nThe age-sex pyramid chart needs to be illustrated for 9 planning areas. If it were to be created side-by-side then the dashboard would appear cluttered. Hence, the most feasible option was to create a 3X3 matrix that would look aesthetically pleasing. To create this view, the following steps were taken\na) Create Parameter: Go to ‘Sheet 1’ and under the ‘Data’ tab, right click and select ‘Create Parameter’. In the dialog box, change the ‘Current value’ to ‘3’ and the ‘Data type’ to ‘Integer’\n\nb) Create Calculated Field: In the ‘Data’ tab, right click and select ‘Create Calculated Field’. Therein type the formula for ‘Index’, ‘Row’ and ‘Column’ as provided in the screenshot below.\n\nc) The matrix outline design is as follows:\n\n\n3.2.3 Creating variables for ‘Male Population’ and ‘Female Population’\nAfter the union of the two sheets on Tableau, the gender column has both males and females. In the age-sex pyramid, we need to display males on one side and females on the other side. To do this, we create two new conditional calculated fields called ‘Male Population and ’Female Population’\n\n3.2.4 Creating Age Group Variable\nThe age groups appear in five year age band, which results in eighteen categories ranging from age 0 to 85 and above. However, for ease of interpretation, it is recommended to have not more than five to six groups. Hence, we create a calculated field called ‘Age Classification’ to further bin the age groups. The rationale has been detailed in point ‘2. The Design’.\n\n3.2.5 Creating the Age-Sex Pyramid\nThe final sheet in Tableau will appear like this:\n\n1. Filters Panel: The only filter that has been applied is by ‘Planning Area’. Drag ‘Planning Area’ under ‘Filter’, then click on the down arrow in ‘Planning Area’ and select ‘Edit Filter’ and navigate to the ‘Top’ tab, under ‘By field’ select ‘Top’ and enter ‘9’ in the field next to it. In ‘by’ select ‘Population’ and the measure as ‘Sum’\n\n\nRow/Column Variables:\na) Drag the following variables in the row and column respectively. In the variable ‘Column’ and ‘Row’, click on the down arrow and make it ‘Discrete’.\n\n\nb) When ‘Female Population’ and ‘Male Population’ is dragged onto columns, ensure that the measure chosen for these variables is ‘SUM’, respectively.\n\nFor both the ‘SUM(Female Population)’ and ‘SUM(Male Population)’, click on the down arrow and ‘Edit Table Calculation’. In the dialog box, select ‘percent of Total’ in ‘Calculation Type’, select ‘Specific Dimensions’ in ‘Compute Using’ and tick on only ‘Age Classification’.\n\nThe Female population on the left hand side needs to appear as a mirror image of the bar chart of the male population. To get the desired butterfly effect, right click on the female population axis and select ‘Edit Axis’ and in ‘Scale’ check on ‘Reversed’, also change the axis title as required.\n\n\n\n3.2.6 Aesthetics\nAesthetics are an important component of visual analytics, hence the charts need to look visually appealing. To ensure that, the font size was standardized and the font colors were kept the same throughout, only the title and axis colors are darker to ensure that they are readable and clear.\na) Grid lines: The grid lines were required to be formatted, so that one can easily follow the age group in each planning area. For this purpose, we right click anywhere within the graph, select ‘Format’ and change the ‘Fields’ in the left pane to ‘Age Classification’, therein navigate to ‘Rows’ and change the grid lines to dotted, repeat the same for ‘Sheet’ tab.\n\nb) Annotating the Planning Areas: Since we decided to use the 3X3 matrix, the planning areas were not automatically named by Tableau, hence the workaround to that, we right click inside each planning region - select ‘Annotate’ and then ‘Area’. Post that, type the name of the planning area in the dialog box that opens. Post that, right click on the planning area box and click ‘Format’, in the ‘Format Annotation’ pane, select ‘None’ for ‘Box’, ‘Shading’ and ‘Border’.\n\n\n\n3.2.7 Making the Dashboard\nTo create the dashboard, first add dashboard from the bottom. Then go to the ‘Dashboard’ pane:\n\nSelect ‘Size’ as ‘Automatic’.\nDrag the final sheet ‘The demographic structure of the 9 most populated areas of Singapore -June 2022’ inside the plain sheet.\nDrag ‘Text’ below the sheet as shown in the screenshot below and write down the text for the age classification and the data source.\nGo to ‘Server’ < ‘Tableau Public’ < ‘Save to Tableau Public’. It will ask for your credentials and then upload this dashboard to Tableau Public!"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-1",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-1",
    "title": "Age-Population Pyramid - Singapore 2022 (Tableau)",
    "section": "Key Finding 1:",
    "text": "Key Finding 1:\nFrom the age-sex pyramid, we can discern with certainty that Singapore has a constrictive population pyramid. This chart appears like a beehive, protruding in the middle and tapering down towards the younger and older population. These charts display smaller proportions of the younger population thereby depicting a population that is ageing and shrinking2. These population pyramids are a common phenomenon in highly developed countries with low birth rates and low death rates. Countries with such a constrictive age-sex pyramid indicate that the population is increasing in high social and economic development with better access to education and healthcare for most of the population3. The ageing population of Singapore is a concern for the government as being a small nation with limited resources, the ageing trend will impact Singapore more acutely. They have introduced policies such as ‘Made for Families’ to support and encourage Singaporeans towards marriage and parenthood. Additionally, policies such as ‘The Refresh of the Action Plan for Successful Ageing and Population’ helps empower the aged population4."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-2",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-2",
    "title": "Age-Population Pyramid - Singapore 2022 (Tableau)",
    "section": "Key Finding 2:",
    "text": "Key Finding 2:\nOne can see a uniform spread through the age profiles across the board, with minute variations observed across the nine planning areas. The dominant age profile is the ‘primary working age’ (PWA) population (aged 25 - 54), accounting for 46.55% of the total population. Children (aged 0 – 14) account for roughly 16% of the total population.\n(a) A higher proportion of PWA and children population in Sengkang, Jurong West and Woodlands: Sengkang records the highest PWA and children population, closely followed by Jurong West and Woodlands, making them the most sought-after dwelling area by the active working population. This can be attributed to the higher presence of children-bearing families that are leveraging the high connectivity of public transport to the central region whilst paying comparatively lower rental rates for the residential properties in these areas.\n(b) A higher proportion of ‘Elderly’ and ‘Oldest-Old’ and a lower proportion of ‘PWA’ and ‘children’ populations in Bedok, Ang Mo Kio, Hougang: The elderly and oldest-old populations account for the lowest proportion in the overall age profile and are more densely populated in Ang Mo Kio, Bedok and Hougang whereas their presence in the planning areas mentioned in 2 (a) is the least. These areas also form a V shape indicative of a higher elderly and aged population indicative of the fact that there is a higher aged population in those areas. These places have abundant amenities that tailor to the needs of the elderly such as coffee shops, marketplaces and leisure places where the aged population can socialise with one another5."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-3",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#key-finding-3",
    "title": "Age-Population Pyramid - Singapore 2022 (Tableau)",
    "section": "Key Finding 3:",
    "text": "Key Finding 3:\nAs we can see in the graphs above, the proportion of females across most age profiles and planning areas is higher than males, albeit marginally. The proportions are relatively equal among the ‘Early Working Age’, ‘Primary Working Age’ and ‘Mature Working Age’ populations.\n(a) Higher Proportion of Females in the elderly and oldest-old categories: There is an increasing trend for the female population increasing post the age of 65, whereas the converse is true for the male population. This clearly implies that female life expectancy is longer than men’s. In fact, this trend has been observed in Singapore since 20106. This difference is more pronounced in areas such as Bedok, Ang Mo Kio, Hougang and Yishun.\n\nLower Proportion of Females in the ‘Children’ population: The proportion of children that are males is higher across the board in the ‘children’ category which could be indicative of higher infant mortality rates for females. This difference is more pronounced in Sengkang, Tampines, Jurong West and Woodlands."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "",
    "text": "In this take-home exercise, we are required to uncover the impact of COVID-19 as well as the global economic and political dynamic from Jan 2020 to Dec 2022 on Singapore bi-lateral trade (i.e. Import, Export and Trade Balance) by using appropriate analytical visualisation techniques learned in Lesson 6: It’s About Time. The focus needs to be on six countries of one’s choice."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#installing-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#installing-r-packages",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "3.1 Installing R Packages",
    "text": "3.1 Installing R Packages\n\n\nCode\npacman::p_load(ggstatsplot, ggthemes, plotly, lubridate, ggpubr, plotly,hrbrthemes, ggrepel, RColorBrewer, gganimate, viridis, ggridges, ggrepel, testthat, hmisc, reshape2, zoo, gridExtra, GGally, patchwork, ggstream, magrittr, bbplot, janitor, magrittr, ggflags, countrycode, ggbraid, tidyverse)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#loading-the-data",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#loading-the-data",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "3.2 Loading the data",
    "text": "3.2 Loading the data\nThe dataset given was in excel, the imports and exports sheet were placed into separate csv files for ease of reading and wrangling data in R.\n\n\nCode\nimports_df <- read_csv(\"data/imports.csv\")\nexports_df <- read_csv(\"data/exports.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#data-wrangling",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "3.3 Data Wrangling",
    "text": "3.3 Data Wrangling\nThe data is short and fat, for ease of visualisation, the data is converted to long and narrow format. For this, we use ‘pivot_longer’ function.\n\n\nCode\n#Pivoting the data in R\nimports_df_long <- imports_df %>%\n  pivot_longer(cols = -Country, names_to = \"date\", values_to = \"import\")\n\nexports_df_long <- exports_df %>%\n  pivot_longer(cols = -Country, names_to = \"date\", values_to = \"export\")\n\n\nMerging the import and export dataframes\n\n\nCode\n# Combine the two datasets by country and month\n\nmerged_df_long <- full_join(imports_df_long, exports_df_long, by = c(\"Country\", \"date\"))\n\n\nCreating a column to calculate the trade balance (exports - imports).\n\n\nCode\nmerged_df_long[is.na(merged_df_long)] <- 0\n\n\n\n\nCode\n#creating trade balance column\nmerged_df_long$trade_balance <- merged_df_long$export - merged_df_long$import\n\n\nConverting the date from character type to the desired date format and creating a column for month and year.\n\n\nCode\nmerged_df_long$date <- ydm(merged_df_long$date)\n\n\n\n\nCode\nmerged_df_long$month <- month(merged_df_long$date)\nmerged_df_long$year <- year(merged_df_long$date)\n\n\n\n\nCode\nmerged_df_long <- merged_df_long %>% mutate(formatted_date = format(date, \"%b %y\"))\n\n\n\n\nCode\nclass(merged_df_long$date)\n\n\nCreating a separate column called category to condense the trade type into one column\n\n\nCode\n#Reshaping the data into long format, again\ndf_long <- gather(merged_df_long, key = \"type\", value = \"value\", import:trade_balance)\n\n\n\n\nCode\n# df_long <- df_long %>%\ndf_long <- df_long %>%\n  mutate(category = case_when(\n    type == \"import\" ~ \"Import\",\n    type == \"export\" ~ \"Export\",\n    type == \"trade_balance\" ~ \"Trade Balance\"\n  ))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#selection-of-countries",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#selection-of-countries",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "3.4 Selection of Countries",
    "text": "3.4 Selection of Countries\nTo narrow down the search for selection of countries, two factors were taken into consideration:\n\nGeographical proximity: countries closer to Singapore are likely to have strong trade relations with Singapore and can have a sizeable impact on Singapore’s trade balance\nEconomic size and significance: countries with greater economic significance can help provide a holistic picture of Singapore’s trade balances and can potentially help identify the key trading partners.\n\nOn the basis of the above factors, the countries chosen are United States, China, Japan, Germany, India and United Kingdom\n\n\nCode\nfiltered_countries <-  c(\"United States\", \"United Kingdom\", \"Mainland China\", \"India\",   \"Germany, Federal Republic Of\", \"Japan\")\n\n\n\n\nCode\nmerged_df_long_six <- filter(merged_df_long, (Country %in% filtered_countries))\n\n\n\n\nCode\ndf_long_six <- filter(df_long, (Country %in% filtered_countries))\n\n\nChanging the name of “Germany, Federal Republic Of” to “Germany” and “Mainland China” to “China”\n\n\nCode\nmerged_df_long_six$Country <- ifelse(grepl(\"Mainland China\", merged_df_long_six$Country), \"China\", merged_df_long_six$Country)\n\nmerged_df_long_six$Country <- ifelse(grepl(\"Germany, Federal Republic Of\", merged_df_long_six$Country), \"Germany\", merged_df_long_six$Country)\n\ndf_long_six$Country <- ifelse(grepl(\"Mainland China\", df_long_six$Country), \"China\", df_long_six$Country)\n\ndf_long_six$Country <- ifelse(grepl(\"Germany, Federal Republic Of\", df_long_six$Country), \"Germany\", df_long_six$Country)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#singapores-trade-overview",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#singapores-trade-overview",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "4.1 Singapore’s Trade Overview",
    "text": "4.1 Singapore’s Trade Overview\n\n\nCode\ndf_long_imex <- df_long %>% \n  filter(category == c(\"Import\", \"Export\"))\n\nmyColours <- c(\"#A6611A\",\"#80CDC1\")\n\nplot1 <- ggplot(data = df_long_imex, aes(x = date, y = value, colour = category)) +\n  \n  geom_line(data = df_long_imex %>% filter(category == \"Import\") %>% filter(Country == \"Total Merchandise Imports\"), size = 1.25) + \n  \n  geom_line(data = df_long_imex %>% filter(category == \"Export\") %>% filter(Country == \"Total Merchandise Exports\"), size = 1.25) + \n  \n  # scale_y_continuous(labels = scales::comma) +\n  \n  scale_y_continuous(breaks = seq(3e+07,7e+07,1e+07), labels = c(\"30\", \"40\", \"50\", \"60\", \"70\")) +\n  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  \n  labs(title = \"Imports and Exports of Singapore from 2020 to 2022\",\n       x = \"Time\", y = \"Value in Millions\", caption = \"Source: Merchandise Trade by Region, Singstat\") + \n  \n  scale_color_manual(values = myColours) + \n  \n  theme_wsj(base_size = 15) + \n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        \n        legend.position = c(0.85, 0.20),\n        legend.title = element_blank(),\n        legend.background = element_blank(),\n        \n        plot.caption = element_text(hjust = 1, size = 8, face = 'italic'),\n        \n        axis.ticks.y = element_line(color = 'black'),\n        axis.ticks.x = element_line(color = 'black'),\n        \n        axis.text = element_text(size = 8, face = \"bold\"),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        \n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\n\n\n\nCode\nggplotly(plot1)\n\n\n\n\n\n\n\n\nCode\n# Get trade balance from Subtracting imports and exports\ntrade_balance_SG <- merged_df_long %>%\n  group_by(date) %>%\n  summarise(TradeBalance = sum(trade_balance[Country == \"Total Merchandise Exports\"]) + sum(trade_balance[Country == \"Total Merchandise Imports\"]))\n\nplot2 <- ggplot(data = trade_balance_SG, aes(x = date, y = TradeBalance)) +\n  \n  geom_line(size = 1.25) + \n\n  scale_y_continuous(breaks = seq(0,8e+06,1e+06), labels = c(\"0\",\"10\",\"20\",\"30\", \"40\", \"50\", \"60\", \"70\", \"80\")) +\n  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  \n  labs(title = \"Trade Balance of Singapore from 2020 to 2022\",\n       x = \"Time\", y = \"Value in Millions\", caption = \"Source: Merchandise Trade by Region, Singstat\") + \n  \n  scale_color_wsj() + \n  \n  theme_wsj(base_size = 15) + \n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        plot.caption = element_text(hjust = 1, size = 8, face = 'italic'),\n        \n        axis.ticks.y = element_line(color = 'black'),\n        axis.ticks.x = element_line(color = 'black'),\n        \n        axis.text = element_text(size = 8, face = \"bold\"),\n        axis.line = element_line(color = \"black\"),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        \n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\n\n\n\nCode\nggplotly(plot2)\n\n\n\n\n\n\nCovid hit the world in December, 2019 and its effects were visible from 2020 beginning. Despite, the adverse effects of covid, Singapore maintained a trade surplus throughout the period of January 2020 to December 2022 i.e. it was exporting more than importing. This is indicative of a sign of competitiveness in the global market. January 2020, May 2022 and August 2022 recorded the lowest trade surplus over the years."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#distribution-of-importsexports-over-the-years-by-country",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#distribution-of-importsexports-over-the-years-by-country",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "4.2 Distribution of Imports/Exports over the years by Country",
    "text": "4.2 Distribution of Imports/Exports over the years by Country\n\n\nCode\n#filter for imports\nimports_six <- df_long_six %>% filter(category == \"Import\")\n\n#filter for exports\nexports_six <- df_long_six %>% filter(category == \"Export\")\n\n\n\n\nCode\nimports_six$year <- as.integer(imports_six$year)\n\nexports_six$year <- as.integer(exports_six$year)\n\n\n\nImportsExports\n\n\n\n\nCode\nggplot(data = imports_six, aes(x = value, y = Country, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_wsj() +\n  \n    labs(title = 'Imports from: {frame_time}',\n       y = \"Value in Millions (SGD)\",\n       x = \"Country\") +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 16, hjust = 1),\n  axis.title.y = element_text(size = 14),\n  axis.text = element_text(size = 12)) +\n  \n  scale_fill_viridis(name = \"value\", option = \"D\") +\n\n  transition_time(imports_six$year) +\n  \n  ease_aes('linear')\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = exports_six, aes(x = value, y = Country, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_wsj() +\n  \n    labs(title = 'Exports from: {frame_time}',\n       y = \"Value in Millions (SGD)\",\n       x = \"Country\") +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 16, hjust = 1),\n  axis.title.y = element_text(size = 14),\n  axis.text = element_text(size = 12)) +\n  \n  scale_fill_viridis(name = \"value\", option = \"D\") +\n\n  transition_time(exports_six$year) +\n  \n  ease_aes('linear')\n\n\n\n\n\n\n\n\nThere has been a gradual increase in imports over the years for all the six countries. United Kingdom, Germany and India have a narrow and long ridgeline plot. United States and China have irregular shaped ridgeline plots with marked fluctuations over the years. For Japan, the ridgeline plot starts out tall and narrow, then shortens in 2021 and then becomes taller again in 2022. This could have been owing to reduced demand by Singapore during late 2020.\nSimilarly, for exports, United Kingdom, Germany and India have a narrow and long ridgeline plot. United States and China have irregular shaped ridgeline plots with marked fluctuations over the years. For Japan, the narrow ridgeline plot shrinks towards the end of 2020 and in 2021 and then becomes long and narrow again. United Kingdom has a long and narrow plot to begin with but over the years, the peak gets longer and narrower."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#singapores-bilateral-trade",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#singapores-bilateral-trade",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "4.3 Singapore’s bilateral trade",
    "text": "4.3 Singapore’s bilateral trade\n\nUnited StatesChinaJapanGermanyUnited KingdomIndia\n\n\n\n\nCode\np1 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"United Kingdom\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"United Kingdom\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"United Kingdom\")) +\n\n  guides(linetype = \"none\") +\n  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n\n  scale_y_continuous(breaks = seq(0 ,1500000, 300000), labels = c(\"0\",\"300\",\"600\",\"900\", \"1200\", \"1500\")) +\n  \n  labs(title = \"Singapore - USA Trade Balance\", x = \"Date\", y = \"Value in Thousands SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n\n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\np1\n\n\n\n\n\n\n\n\n\nCode\np2 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"China\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"China\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"China\")) +\n\n  guides(linetype = \"none\") +\n  \n   scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n\n   scale_y_continuous(breaks = seq(3000000,10000000,1000000), labels = c(\"3\",\"4\",\"5\",\"6\", \"7\", \"8\", \"9\", \"10\")) +\n  \n  labs(title = \"Singapore-USA trade balance\", x = \"Date\", y = \"Value in Millions SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n\n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\n\np2\n\n\n\n\n\n\n\n\n\nCode\np3 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"Japan\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"Japan\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"Japan\")) +\n\n  guides(linetype = \"none\") +\n  \n   scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n\n  scale_y_continuous(breaks = seq(0,4000000,500000), labels = c(\"0\",\"5\",\"10\",\"15\", \"20\", \"25\", \"30\", \"35\", \"40\")) +\n  \n  labs(title = \"Singapore - Japan trade balance\", x = \"Date\", y = \"Value in Thousands SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n\n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\np3\n\n\n\n\n\n\n\n\n\nCode\np4 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"Germany\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"Germany\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"Germany\")) +\n\n  guides(linetype = \"none\") +\n  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n\nscale_y_continuous(breaks = seq(0,1500000,250000), labels = c(\"0\",\"25\",\"50\",\"75\", \"100\", \"125\", \"150\")) +\n  \n  labs(title = \"Singapore - Germany trade balance\", x = \"Date\", y = \"Value in Thousands SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n  \n    theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\n\n\np4\n\n\n\n\n\n\n\n\n\nCode\np5 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"United Kingdom\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"United Kingdom\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"United Kingdom\")) +\n\n  guides(linetype = \"none\") +\n  \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n\n scale_y_continuous(breaks = seq(0,1500000, 250000), labels = c(\"0\",\"25\",\"50\",\"75\", \"100\", \"125\", \"150\")) +\n  \n  labs(title = \"Singapore - United Kingdom trade balance\", x = \"Date\", y = \"Value in Thousands SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n\n    theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\np5\n\n\n\n\n\n\n\n\n\nCode\np6 <- ggplot() +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"India\", category == \"Import\")) +\n\n  geom_line(aes(x = date, y = value, linetype = category), data = df_long_six %>% filter(Country == \"India\", category == \"Export\")) +\n\n    geom_braid(aes(date, ymin = import, ymax = export, fill = import < export), data = merged_df_long %>% filter(Country == \"India\")) +\n\n  guides(linetype = \"none\") +\n\n scale_y_continuous(breaks = seq(0,2000000,500000), labels = c(\"0\",\"50\",\"100\",\"150\", \"200\")) +\n  \n  labs(title = \"Singapore - India trade balance\", x = \"Date\", y = \"Value in Thousands SGD\", caption = \"Source: Merchandise Trade by Region, Singstat\") +\n\n  theme_wsj() +\n\n  scale_fill_manual(values = c(\"#63803e\", \"#0e2e47\"), name = \"Trade Balance\", labels = c(\"Deficit\", \"Surplus\")) +\n\n    theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 15, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 1, face = 'italic', size = 8),\n        legend.position = 'bottom',\n\n        panel.grid.major.y = element_blank(),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n\n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 10),\n        axis.title.y = element_text(angle = 90, vjust = 1.03),\n        axis.text = element_text(size = 8),\n        axis.text.x = element_text(angle = 90),\n\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\np6\n\n\n\n\n\n\n\n\nSingapore’s trade relations with economically large and significant country indicates that it is largely an importer of products from these countries than an exporter. It does volume importing and exporting with China, with their trade deficit and surplus oscillating over the periods. With India, United States and United Kingdom, a large trade deficit gap is observed in comparison to Japan and Germany"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#proportion-of-bilateral-trades",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#proportion-of-bilateral-trades",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "4.4 Proportion of bilateral trades",
    "text": "4.4 Proportion of bilateral trades\n\n\nCode\n#different years\nyear2020 <- df_long_six %>% filter(year == \"2020\", category == c(\"Import\", \"Export\"))\nyear2021 <- df_long_six %>% filter(year == \"2021\", category == c(\"Import\", \"Export\"))\nyear2022 <- df_long_six %>% filter(year == \"2022\", category == c(\"Import\", \"Export\"))\n\n\n\n\nCode\n# calculate total value by country and type\ndf_sum2020 <- aggregate(value ~ Country + category, data = year2020, sum)\ndf_sum2021 <- aggregate(value ~ Country + category, data = year2021, sum)\ndf_sum2022 <- aggregate(value ~ Country + category, data = year2022, sum)\n\n# calculate proportion of value by country and type\ndf_sum2020$prop <- df_sum2020$value / tapply(df_sum2020$value, df_sum2020$Country, sum)[df_sum2020$Country]\n\ndf_sum2021$prop <- df_sum2021$value / tapply(df_sum2021$value, df_sum2021$Country, sum)[df_sum2021$Country]\n\ndf_sum2022$prop <- df_sum2022$value / tapply(df_sum2022$value, df_sum2022$Country, sum)[df_sum2022$Country]\n\n\n\n202020212022\n\n\n\n\nCode\n# create bar plot\nyp1 <- ggplot(df_sum2020, aes(x = Country, y = prop, fill = category)) +\n  \n  geom_bar(position = \"stack\", stat = \"identity\") +\n  \n  labs(title = \"Proportion of Imports/Exports by Country - 2020\", x = \"Country\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent) + \n  theme_wsj() + \n  scale_fill_manual(values = c(\"#263d2b\", \"#91790d\")) + \n  \n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 14, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 0, face = 'italic'),\n        legend.position = 'bottom',\n\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 10),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\nggplotly(yp1)\n\n\n\n\n\n\n\n\n\n\nCode\nyp2 <- ggplot(df_sum2021, aes(x = Country, y = prop, fill = category)) +\n  \n  geom_bar(position = \"stack\", stat = \"identity\") +\n  \n  labs(title = \"Proportion of Imports/Exports by Country - 2021\", x = \"Country\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent) + \n  theme_wsj() + \n  scale_fill_manual(values = c(\"#263d2b\", \"#91790d\")) + \n  \n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 14, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 0, face = 'italic'),\n        legend.position = 'bottom',\n\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 10),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\nggplotly(yp2)\n\n\n\n\n\n\n\n\n\n\nCode\nyp3 <- ggplot(df_sum2022, aes(x = Country, y = prop, fill = category)) +\n  \n  geom_bar(position = \"stack\", stat = \"identity\") +\n  \n  labs(title = \"Proportion of Imports/Exports by Country - 2022\", x = \"Country\", y = \"Proportion\") +\n  scale_y_continuous(labels = scales::percent) + \n  theme_wsj() + \n  scale_fill_manual(values = c(\"#263d2b\", \"#91790d\")) + \n  \n  theme(\n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 14, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 0, face = 'italic'),\n        legend.position = 'bottom',\n\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 10),\n\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 8))\n\nggplotly(yp3)\n\n\n\n\n\n\n\n\n\nOver the years, the proportion of imports and exports with each country has largely remained the same. The trend observed here is that of the countries chosen, China & Singapore and USA & Singapore have balances import-export trades, India recorded more exports than imports and United Kingdom recorded more imports than exports over the years."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#comparing-mean-values-across-countries",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take-Home_Ex04.html#comparing-mean-values-across-countries",
    "title": "Unpacking International Trade Relations with Singapore 2020-22",
    "section": "4.5 Comparing mean values across Countries",
    "text": "4.5 Comparing mean values across Countries\n\n\nCode\navg_imp <- df_long_six %>% \n  filter(category == \"Import\") %>% \n  mutate(avg_imp = mean(value, na.rm = TRUE)) %>% \n  group_by(Country) %>% \n  mutate(country_avg_imp = mean(value, na.rm = TRUE)) %>%\n  ungroup()\n\navg_exp <- df_long_six %>% \n  filter(category == \"Export\") %>% \n  mutate(avg_exp = mean(value, na.rm = TRUE)) %>% \n  group_by(Country) %>% \n  mutate(country_avg_exp = mean(value, na.rm = TRUE)) %>%\n  ungroup()\n\n\n\nMean ImportsMean Exports\n\n\n\n\nCode\nmyplot <- avg_imp %>%\nggplot(aes(x = reorder(Country, value), y = value, color = Country)) +\ngeom_jitter(aes(size = year), alpha = 0.7, width = 0.15) +\ngeom_hline(aes(yintercept = avg_imp), color = \"black\", size = 2)+\ngeom_segment(aes(x = Country, xend = Country, y = country_avg_imp, yend = avg_imp), size = 2, color = \"black\") +\n  labs(title = \"Comparing Mean Values across Countries\", \n       x = \"Countries\",\n       y = \"Value (SGD)\") +\n#ggflags::geom_flag(aes(x = country_name, y = country_avg_trust), size = 10) + \n  coord_flip() +\n  \n  scale_color_viridis(option = \"inferno\", discrete = TRUE) + \n  \n    theme(panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        \n        axis.line = element_line(color = \"black\"))\n\nmyplot\n\n\n\n\n\n\n\n\n\nCode\nmyplot1 <- avg_exp %>%\nggplot(aes(x = reorder(Country, value), y = value, color = Country)) +\ngeom_jitter(aes(size = year), alpha = 0.7, width = 0.15) +\ngeom_hline(aes(yintercept = avg_exp), color = \"black\", size = 2)+\ngeom_segment(aes(x = Country, xend = Country, y = country_avg_exp, yend = avg_exp), size = 2, color = \"black\") +\n#ggflags::geom_flag(aes(x = country_name, y = country_avg_trust), size = 10) + \n  coord_flip() + \n  scale_color_viridis(option = \"inferno\", discrete = TRUE) +\n  \n    theme(panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_blank(),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        \n        axis.line = element_line(color = \"black\"))\n\nmyplot1 \n\n\n\n\n\n\n\n\nOver the years, the imports from China and United States have been greater than the mean value, with imports from Japan transcending the mean value over the years, specifically from 2021, whereas the other countries the import value has been below average. The least value of imports is observed for India.\nOver the years, the exports from China and United States have been greater than the mean value. The least value of exports is observed for United Kingdom."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "",
    "text": "The task is to uncover the salient patterns of the resale prices of public housing property by residential towns and estates in Singapore by using appropriate analytical visualisation techniques learned in Lesson 4: Fundamentals of Visual Analytics. Students are encouraged to apply appropriate interactive techniques to enhance user and data discovery experiences.\nFor the purpose of this study, the focus should be on 3-ROOM, 4-ROOM and 5-ROOM types. You can choose to focus on either one housing type or multiple housing types. The study period should be on 2022."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#install-requisite-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#install-requisite-r-packages",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "3.1 Install Requisite R Packages",
    "text": "3.1 Install Requisite R Packages\n\npacman::p_load(ggstatsplot, ggthemes, plotly, corrplot, lubridate, ggpubr, plotly, treemap, d3treeR, hrbrthemes, ggrepel, RColorBrewer, gganimate, viridis, ggridges, ggrepel, testthat, hmisc, tidyverse)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-the-resale-flat---singapore-dataset",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#loading-the-resale-flat---singapore-dataset",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "3.2 Loading the Resale Flat - Singapore Dataset",
    "text": "3.2 Loading the Resale Flat - Singapore Dataset\n\nsg_re_price <- read_csv(\"data/resale_flat_prices.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-prep",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-prep",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "3.3 Data Prep",
    "text": "3.3 Data Prep\n\n\n\n\n\n\n\n\nIssues\nDescription\nResolution\n\n\n\n\nOutliers\nThe resale price has outliers where the price goes up 141800. The top 10% of resale price are outliers.\nOutliers should be excluded from the data. Anything falling above the 3rd quartile is filtered out from the data. (3.3.4)\n\n\nVariable type\nDate is available in the form of ‘YYYY - MM’ which is not readable in R\nFormat date, seperate month into month and year. (3.3.1)\n\n\nNew variables\nLease start date and lease years cannot be used for analysis. Additionally, floor area and reslae price can be used to calculate price per square meter to enhance analysis.\nprice_psm, priceK and property age are calculated. (3.3.2)\n\n\n\n\n3.3.1. Separating the date into month and year\n\n\nCode\nsg_re_price <- sg_re_price %>% \n  separate(month, c(\"Year\", \"Month\"), sep = \"-\")\n\n\n\n\nCode\nsg_re_price$Year <- strtoi(sg_re_price$Year)\nsg_re_price$Month <- strtoi(sg_re_price$Month)\n\n\n\n\n3.3.2 Creating new variables\n\n\nCode\nsg_re_price <- sg_re_price %>%\n  mutate(price_psm = round(resale_price / floor_area_sqm)) %>%\n  mutate(priceK = round(resale_price / 1000)) %>%\n  mutate(property_age = round(2022 - lease_commence_date))\n\n\n\n\n3.3.3 Considering data for year 2022 and 3-room, 4-room and 5-room flat types\n\n\nCode\nsg_re_price_2022 <- sg_re_price %>%\n  filter(Year == 2022, flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\n\n\n\n3.3.4 Summary of Data\nThe filtered data has 24, 372 observations. Please find below the summary statistics for each of the variables.\n\npsych::describe(sg_re_price_2022)\n\n                    vars     n      mean        sd median   trimmed       mad\nYear                   1 24372   2022.00      0.00   2022   2022.00      0.00\nMonth                  2 19922      6.05      3.65      5      5.93      2.97\ntown*                  3 24372     15.12      7.88     17     15.47      8.90\nflat_type*             4 24372      2.02      0.73      2      2.02      1.48\nblock*                 5 24372   1059.67    706.08   1018   1035.46    886.59\nstreet_name*           6 24372    275.03    165.99    275    274.60    212.01\nstorey_range*          7 24372      3.36      2.09      3      3.08      1.48\nfloor_area_sqm         8 24372     94.08     19.32     93     93.99     25.20\nflat_model*            9 24372      6.78      2.63      6      6.52      2.97\nlease_commence_date   10 24372   1997.46     14.98   1998   1997.83     20.76\nremaining_lease*      11 24372    376.27    180.22    377    380.97    247.59\nresale_price          12 24372 536394.11 157999.71 515000 520463.70 133434.00\nprice_psm             13 24372   5735.91   1363.09   5368   5511.74    913.28\npriceK                14 24372    536.40    158.00    515    520.47    133.43\nproperty_age          15 24372     24.54     14.98     24     24.17     20.76\n                       min     max   range  skew kurtosis      se\nYear                  2022    2022       0   NaN      NaN    0.00\nMonth                    1      12      11  0.31    -1.21    0.03\ntown*                    1      26      25 -0.31    -1.16    0.05\nflat_type*               1       3       2 -0.02    -1.13    0.00\nblock*                   1    2457    2456  0.21    -1.16    4.52\nstreet_name*             1     552     551  0.02    -1.26    1.06\nstorey_range*            1      17      16  1.66     4.36    0.01\nfloor_area_sqm          51     159     108 -0.06    -0.85    0.12\nflat_model*              1      16      15  0.71    -0.39    0.02\nlease_commence_date   1967    2019      52 -0.03    -1.33    0.10\nremaining_lease*         1     638     637 -0.04    -1.32    1.15\nresale_price        200000 1418000 1218000  1.09     1.81 1012.07\nprice_psm             3333   14731   11398  1.70     3.30    8.73\npriceK                 200    1418    1218  1.09     1.81    1.01\nproperty_age             3      55      52  0.03    -1.33    0.10\n\n\n\n\n3.3.5. Historgram and dealing with outliers\nTo check the normality of data, we chart out histograms for resale price (in 1000s), Floor area, Property age and price per square meter. We observe that there is a distinct right skew for price per square and resale price ((in 1000s). Our aim is for the data to be normal or as normal as possible.\n\n\nCode\nset.seed(1234)\n\n#need to change bar colors, line color, ggtitles, gglabs\n\np1 <- gghistostats(\n  data = sg_re_price_2022,\n  x = priceK,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"Resale Price in Thousands\") +\n  \n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n        \np2 <- gghistostats(\n  data = sg_re_price_2022,\n  x = floor_area_sqm,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"Floor area (sqm)\"\n) +\n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n\np3 <- gghistostats(\n  data = sg_re_price_2022,\n  x = property_age,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"Property Age\"\n) +\n  theme_minimal() +\n  \n  theme(text = element_text(family = \"Garamond\"))\n\np4 <- gghistostats(\n  data = sg_re_price_2022,\n  x = price_psm,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"Resale price psm\"\n) +\n  theme_minimal()+\n  \n  theme(text = element_text(family = \"Garamond\"))\n\n\n3. Remove outliers: The rule of thumb for outliers is that data points over the third quartile are eliminated. We calculate the upper limit and interquartile range for both the variables and then filter out the outliers.\n\n\nCode\n# Calculating the upper limit and Interquartile range for Price in 1000s and price per square meter\n\nIQR_priceK = IQR(sg_re_price_2022$priceK)\nIQR_price_psm = IQR(sg_re_price_2022$price_psm)\n\npriceK_upper = quantile(sg_re_price_2022$priceK,probs = 0.9)+1.5*IQR_priceK\nprice_psm_upper = quantile(sg_re_price_2022$price_psm,probs = 0.9)+1.5*IQR_price_psm\n\n# Filtering out the outliers\nsg_re_price_2022_v1 <- sg_re_price_2022 %>%\n           filter ((priceK <= priceK_upper) &\n           (price_psm<= price_psm_upper))\n\n\n4. View data after outliers are removed\n\n\nCode\n#To plot normality, we need to ascertain the mean and std. deviation\n\nmean_priceK = mean(sg_re_price_2022_v1$priceK)\nstd_priceK = sd(sg_re_price_2022_v1$priceK)\n\npriceK_norm <- ggplot(sg_re_price_2022_v1, aes(priceK))+\n  geom_histogram(aes(y=..density..), fill = '#133337', color = '#eeeeee')+\n  \n  stat_function(fun = dnorm, args = list(mean = mean_priceK, sd = std_priceK), col=\"#66cccc\", size = .7)+\n  \n  labs(title = 'Normality Check on Distribution of Resale Price', \n       x = \"Resale price in Thousands (SGD)\")+\n  \n  theme_minimal()+\n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.1, size = 10, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        \n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_line(linewidth = 0.25, linetype = 'dashed', colour = '#bebebe'),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        \n        \n        axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x = element_text(size = 8, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.4, size = 10, face = \"bold\"))\n\n\n\n\nCode\n#To plot normality, we need to ascertain the mean and std. deviation\n\nmean_price_psm = mean(sg_re_price_2022_v1$price_psm)\nstd_price_psm = sd(sg_re_price_2022_v1$price_psm)\n\nprice_per_psm_norm <- ggplot(sg_re_price_2022_v1, aes(price_psm))+\n  geom_histogram(aes(y=..density..), fill = '#133337', color = '#eeeeee')+\n  stat_function(fun = dnorm, args = list(mean = mean_price_psm, sd = std_price_psm), col=\"#66cccc\", size = .7)+\n  \n  labs(title = 'Normality Check on Distribution of Resale Price psm', \n       x = \"Resale price per sqm (SGD)\", \n       caption = \"Source: Data.gov.sg\")+\n  \n  theme_minimal()+\n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.1, size = 10, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        plot.caption = element_text(face = \"italic\", size = 10),\n        \n        panel.background = element_rect(fill = 'white'),\n        panel.grid.major.x = element_line(linewidth = 0.25, linetype = 'dashed', colour = '#bebebe'),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        \n        \n        axis.text.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x = element_text(size = 8, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 10, face = \"bold\"))\n\n\n\n\nCode\npriceK_norm + price_per_psm_norm\n\n\n\n\n\nThe distribution for resale price and resale price psm appears to be less right skewed post removing outliers!"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#flat-type",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#flat-type",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "4.1 Flat Type",
    "text": "4.1 Flat Type\n\n4.1.1 Resale prices over the years by flat type\nRidgeline plot is a set of overlapped density plots, and it helps us to compare multiple distirbutions among dataset. They are useful for visualizing changes in distributions over time or space.\nFrom this graph we learn:\n\nThe resale prices are more or less contained from 2017 to 2020. There is a marked increase (sharp right movement of all curves) in prices for all flat types in 2020, then a gradual increase is observed from 2021.\nThere is a slow increase in prices observed over 2022. The distribution of 5-room flats observes rapid fluctuations in the first quarter of the year. 3-room flats has an even distribution throughout and 4-room flats observe minor fluctuations over 2022.\n\n\n2017 - 20232022\n\n\n\n\nCode\nsg_re_price_flat <- sg_re_price %>%\n  filter(flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\nggplot(data = sg_re_price_flat, aes(x = priceK, y = flat_type, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_minimal() +\n  \n    labs(title = 'Resale Prices by Flat Type: {frame_time}',\n       y = \"Resale Price in Thousands (SGD)\",\n       x = \"Flat Type\") +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10),\n  axis.text = element_text(size = 8)) +\n  \n  scale_fill_viridis(name = \"priceK\", option = \"D\") +\n\n  transition_time(sg_re_price_flat$Year) +\n  ease_aes('linear')\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sg_re_price_2022_v1, aes(x = priceK, y = flat_type, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_minimal() +\n  \n    labs(title = 'Resale Prices by Flat Type in 2022, Month: {frame_time}',\n       x = \"Flat Type\",\n       y = \"Resale Price in Thousands (SGD)\") +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10),\n  axis.text = element_text(size = 8)) +\n  \n  scale_fill_viridis(name = \"priceK\", option = \"D\") +\n  \n  transition_time(sg_re_price_2022_v1$Month) +\n  ease_aes('linear')\n\n\n\n\n\n\n\n\n\n\n4.1.2 Proportion of flat types in Singapore\nThe data clearly shows that 4-room apartments are the most popular in Singapore, accounting for nearly 50% of the flat types. 5-room and 3-rooms have relatively the same proportion of flats in Singapore - accounting for a quarter of each!\n\n\nCode\nHDB_count  <- sg_re_price_2022_v1 %>%\n  group_by(flat_type) %>%\n  summarize(\n    count = n()) %>% \n  mutate(hdb_pie_pct = round(count/sum(count)*100)) %>% \n  mutate(ypos_p = rev(cumsum(rev(hdb_pie_pct))),\n         pos_p = hdb_pie_pct/2 + lead(ypos_p,1),\n         pos_p = if_else(is.na(pos_p), hdb_pie_pct/2, pos_p))\n\nggplot(HDB_count, aes(x = \"\" , y = hdb_pie_pct, fill = fct_inorder(flat_type))) +\n  geom_col(width = 1, color = 1) +\n  coord_polar(theta = \"y\") +\n  scale_fill_brewer(palette = \"YlGnBu\") +\n  geom_label_repel(data = HDB_count,\n                   aes(y = pos_p, label = paste0(hdb_pie_pct, \"%\")),\n                   size = 4.5, nudge_x = 1, color = c(1, 1, 1), show.legend = FALSE) +\n  guides(fill = guide_legend(title = \"Flat Type\")) +\n  labs(title = \"Proportion of Flat Types in Singapore\")+\ntheme(legend.position = \"bottom\")+\ntheme_minimal()\n\n\n\n\n\n\n\n4.1.3 Boxplot of Resale price by flat types\nIn descriptive statistics, a box plot or boxplot is a type of chart often used for EDA. Box plots visually show the distribution of numerical data and skewness through displaying the data quartiles (or percentiles) and averages.\nWhen the median line appears in the middle of the boxplot, the data is normally distributed. We observe that:\n\nAs expected, the median is the highest for 5-room flats, followed by 4-room and lastly 3-room flats.\nThe dispersion (interquartile range) is the smallest for 3-room flats and largest for 5 room flats. This suggests that the 3 room flats are spread out around the median in comparison to 4 or 5 room flats.\nThere is higher presence of outliers for 3-room flats, some even going up to 930000 (3rd quartile for 5-room flat)\n\n\n\nCode\nt <- list(\n  family = \"Garamond\",\n  size = 19,\n  face = \"bold\")\n\nt1 <- list(\n  family = \"Garamond\",\n  size = 15,\n  face = \"bold\")\n\nfig <- plot_ly(\n  data = sg_re_price_2022_v1,\n  y = ~priceK,\n  type = \"box\",\n  color = ~flat_type,\n  colors = \"YlGnBu\",\n  showlegend = FALSE,\n  boxmean = TRUE\n) %>% \n  layout(title= list(text = \"Boxplot of resale price in Thousands by flat type\",font = t1),\n         xaxis = list(title = list(text ='Flat Type', font = t1)),\n         yaxis = list(title = list(text ='Resale Price in Thousands (SGD)', font = t1)))\n\nfig\n\n\n\n\n\n\n\n\n4.1.4 Is there an increase in resale price monthly by flat type?\nMedia outlets have been reporting that there has been a dramatic increase in the resale prices for HDBs. Real estate data is known to have many outliers, hence the best metric for comparison over time and distribution is median (they are unaffected by outliers). In the graph below, we observe that there is no discernible difference in the median prices, monthly, for 3 room, 4 room, 5 room flats,\n\nFlat Type3 Room4 Room5 Room\n\n\n\n\nCode\nggplot(na.omit(sg_re_price_2022_v1),aes(x = flat_type, y = priceK)) +\n  \n  geom_boxplot(aes(fill = as.factor(Month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"mean\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly Resale prices by Flat Types\",\n       y = \"Resale price (1000s)\",\n       x = \"Flat Type\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nCode\nna.omit(sg_re_price_2022_v1) %>% \n  filter(flat_type == \"3 ROOM\") %>% \n  ggplot(aes(x = flat_type, y = priceK)) +\n  \n  geom_boxplot(aes(fill = as.factor(Month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"mean\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly Resale prices by Flat Types\",\n       y = \"Resale price (1000s)\",\n       x = \"Flat Type\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nCode\nna.omit(sg_re_price_2022_v1) %>% \n  filter(flat_type == \"4 ROOM\") %>% \n  ggplot(aes(x = flat_type, y = priceK)) +\n  \n  geom_boxplot(aes(fill = as.factor(Month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"mean\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly Resale prices by Flat Types\",\n       y = \"Resale price (1000s)\",\n       x = \"Flat Type\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nCode\nna.omit(sg_re_price_2022_v1) %>% \n  filter(flat_type == \"5 ROOM\") %>% \n  ggplot(aes(x = flat_type, y = priceK)) +\n  \n  geom_boxplot(aes(fill = as.factor(Month)), color = \"#c0c0c0\") +\n  \n  stat_summary(fun.y = \"mean\", geom = \"point\", color = \"black\") +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Paired\") +\n\n labs( title = \"Monthly Resale prices by Flat Types\",\n       y = \"Resale price (1000s)\",\n       x = \"Flat Type\",\n       fill = \"Month\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.5, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#planning-area",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#planning-area",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "4.2 Planning Area",
    "text": "4.2 Planning Area\n\n4.2.1 Resale price by planning area over time\nThe ridge plot showcases:\n\nThe resale prices across planning areas are more or less contained from 2017 to 2020. There is a marked increase (sharp right movement of all curves) in prices for all planning areas in 2020, then a gradual increase is observed from 2021.\nThe distribution across planning areas is more or less constant till 2020. Post 2020, most of the distributions are flattening out indicating that the prices are widely distributed over these time periods. Bukit Timah, Central Area, Queenstown have 2 - 3 humps in their distribution implying that they have properties in the lower, medium and upper range.\n\n\n2017 - 20232022\n\n\n\n\nCode\nggplot(data = sg_re_price, aes(x = priceK, y = town, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_minimal() +\n    \n  labs(title = 'Resale Prices by Planning Area: {frame_time}') +\n  transition_time(sg_re_price$Year) +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10, angle = 360),\n  axis.text = element_text(size = 8)) +\n  \n  scale_fill_viridis(name = \"priceK\", option = \"D\") +\n\n  ease_aes('linear')\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = sg_re_price_2022_v1, aes(x = priceK, y = town, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_minimal() +\n  \n  labs(title = 'Resale Prices by Planning Area in 2022, Month: {frame_time}') +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  \n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10, angle = 360),\n  axis.text = element_text(size = 8)) +\n  \n  scale_fill_viridis(name = \"priceK\", option = \"D\") +\n  \n  transition_time(sg_re_price_2022_v1$Month) +\n  ease_aes('linear')"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#flat-type-comparison-by-planning-area",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#flat-type-comparison-by-planning-area",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "4.3 Flat type comparison by planning area",
    "text": "4.3 Flat type comparison by planning area\n\n4.3.1 Proportion of Flat types by Planning area in Singapore\nWe now look into the proportion of flat types by planning areas. We observe that:\n\nToa Payoh, Ang Mo Kio, Bedok, Central Area have the highest proprtion of 3-room flats, whereas Bukit Timah and Paris Ris have the least.\nYishun, Woodlands, Serangoon have the highest proportion of 4-room flats.\nSengkang, Punggol have the highest proportion of 5-room flats.\n\n\nPlotData\n\n\n\n\nCode\nprop_sg <- sg_re_price_2022_v1%>%\ngroup_by(town, flat_type) %>%\nsummarize(ft_count = n())%>%\nmutate(ft_pct = scales::percent(ft_count/sum(ft_count)))\n\nprop <- ggplot(prop_sg, \n                aes(town, ft_count, fill = flat_type)) + \n  geom_bar(stat=\"identity\") +\n\n  labs(title = \"Proportion of Flat types by Planning area in Singapore\", x = \"Planning Area\", y = \"Count\", fill = \"Flat Type\") +\n  \n  theme_minimal() +\n  \n  scale_fill_viridis(discrete = T, option = \"E\") +\n  \n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.4, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        axis.text = element_text(size = 8, face = \"bold\"),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\"))\n\nggplotly(prop)\n\n\n\n\n\n\n\n\n\n\nCode\nprop_sg <- sg_re_price_2022_v1%>%\ngroup_by(town, flat_type) %>%\nsummarize(ft_count = n())%>%\nmutate(ft_pct = scales::percent(ft_count/sum(ft_count)))\n\nprop_sg\n\n\n# A tibble: 78 × 4\n# Groups:   town [26]\n   town        flat_type ft_count ft_pct\n   <chr>       <chr>        <int> <chr> \n 1 ANG MO KIO  3 ROOM         524 56%   \n 2 ANG MO KIO  4 ROOM         287 30%   \n 3 ANG MO KIO  5 ROOM         132 14%   \n 4 BEDOK       3 ROOM         555 43.7% \n 5 BEDOK       4 ROOM         462 36.4% \n 6 BEDOK       5 ROOM         253 19.9% \n 7 BISHAN      3 ROOM          65 17%   \n 8 BISHAN      4 ROOM         200 51%   \n 9 BISHAN      5 ROOM         124 32%   \n10 BUKIT BATOK 3 ROOM         281 35%   \n# … with 68 more rows\n\n\n\n\n\n\n\n4.3.2 Resale prices of different flat types by planning area\nThe dumbell chart showcases the minimum and maximum prices for each planning area.\n\nWoodlands, Sembawang, Choa Chu Kang provide more affordable flats with their maximum price being below SGD 800,000. Conversely, most of the other regions have wider distribution of prices ranging from mid to exorbitant.\n\n\n\nCode\nareas = unique(sg_re_price_2022_v1$town)\nPA = c()\nmin_price = c()\nmax_price = c()\n\nfor(area in areas){\n  df <- sg_re_price_2022_v1[sg_re_price_2022_v1$town == area,]\n  PA = c(PA, area)\n  min_price = c(min_price, min(df$priceK))\n  max_price = c(max_price, max(df$priceK))\n}\n\ndf <- data.frame(\"Planning_Area\" = PA, \"Min_Price\" = min_price, \"Max_Price\" = max_price, check.names=FALSE)\n\n\n\n\nCode\ndumbell <- plot_ly(df) %>% \n add_segments(x = ~Min_Price, xend = ~Max_Price, y = ~Planning_Area, yend = ~Planning_Area, showlegend = FALSE) %>% \n add_markers(x = ~Min_Price, y = ~Planning_Area, name = \"Min\", color = I(\"#e66819\")) %>% \n add_markers(x = ~Max_Price, y = ~Planning_Area, name = \"Max\", color = I(\"#bf0d31\")) %>% \n layout(\n    title = \"Resale Price in 1000s Difference Across Planning Areas\",\n    xaxis = list(title = \"Resale Price in 1000s (SGD)\"),\n    yaxis = list(title = \"Planning Area\"),\n    margin = list(l = 70)\n  )\n\ndumbell\n\n\n\n\n\n\nThe dumbell chart is a parochial view of the range of resale price. Hence, we further delve into the box and whiskers plot of 3-room, 4-room, and 5-room flat types across the planning regions.\nWe see that areas such as Jurong West and Tampines have the widest price range for 5-room type flats, especially towards the lucrative side of the price. In Marine Parade, the 5-room flat types were significantly higher priced than 3-room and 4-room type flats. The opposite was true for areas such as Serangoon.\n\n\nCode\n#have to change theme and everything else\n\np <- ggplot(data = sg_re_price_2022_v1, aes(x = town, y = priceK)) +\n  \n  geom_boxplot(aes(fill = as.factor(flat_type))) +\n  \n  theme_minimal() +\n  \n  scale_fill_brewer(palette = \"Dark2\") +\n\n labs( title = \"Resale prices in Thousands in 2022 by planning area\",\n       fill = \"Flat Type\",\n       y = \"Resale price (1000s)\",\n       x = \"Planning Area\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 12, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 8, face = \"bold\"),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n        axis.title.x = element_text(hjust = 0.5, size = 12, face = \"bold\", color = \"#899499\"),\n        axis.title.y = element_text(hjust = 0.5, size = 12, face = \"bold\", color = \"#899499\"))\n\nggplotly(p)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#area-age-by-flat-type",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#area-age-by-flat-type",
    "title": "Is the Media Noise around Re-sale price (2022) right?",
    "section": "4.2 Area & Age by Flat Type",
    "text": "4.2 Area & Age by Flat Type\n\n4.2.1 Correlation for Area, Age with Resale Price\nThe correlation chart shows that there is a positive relationship between area of property and resale price i.e. larger the property size gets, higher the resale price. Resale price and age have a weak negative relationship.\n\nArea CorrelationAge Correlation\n\n\n\n\nCode\nggscatterstats(\n data = sg_re_price_2022_v1,\nx = floor_area_sqm,\ny = priceK,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(title = 'Correlation of resale price (in 000s) and floor area (sqm)', x = \"Floor Area\", y = \"Resale Price in 000s\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nCode\nggscatterstats(\n data = sg_re_price_2022_v1,\nx = property_age,\ny = priceK,\nmarginal = FALSE) +\n  \n  theme_minimal() +\n  \n  labs(title = 'Correlation of resale price (in 000s) and floor area (sqm)', x = \"Floor Area\", y = \"Resale Price in 000s\") +\n\ntheme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'),\n        plot.margin = margin(20, 20, 20, 20),\n        legend.position = \"bottom\",\n        \n        axis.text = element_text(size = 10, face = \"bold\"),\n        axis.title = element_text(size = 12, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n4.2.2 Treemap for Age and Area\nThrough the treemap, we see on overall glimpse of flat types by prices per square meter and resale prices in 000s across all planning areas.\n\nArea TreemapAge Treemap\n\n\n\n\nCode\ntreemap_area <- treemap (sg_re_price_2022_v1,\n        index= c(\"flat_type\", \"town\"),\n        vSize= \"floor_area_sqm\",\n        vColor = \"priceK\",\n        type=\"manual\",\n        palette = mako(5),\n        border.col = c(\"black\", \"white\"),\n        title=\"Properties for resale\",\n        title.legend = \"Median Price (1000s)\"\n        )\n\n\n\n\n\n\n\n\n\nCode\ntreemap_age <- treemap (sg_re_price_2022_v1,\n        index= c(\"flat_type\", \"town\"),\n        vSize= \"property_age\",\n        vColor = \"priceK\",\n        type=\"manual\",\n        palette = \"Blues\",\n        title=\"Properties for resale\",\n        title.legend = \"Median Price (1000s)\"\n        )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Age-Population Pyramid - Singapore 2022 (RStudio)",
    "section": "",
    "text": "The task is to critique the Take-Home exercise 1 of any of one our peers in terms of what could have been improved with respect to clarity and aesthetics to make it a compelling visual graph. The alternate proposed graph needs to be sketched using the visualisation data design principles and industry best practices. the graph needs to be reproduced in R using ggplot2 and tidyverse packages."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#clarity",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#clarity",
    "title": "Age-Population Pyramid - Singapore 2022 (RStudio)",
    "section": "2.1 Clarity",
    "text": "2.1 Clarity\n\n2.1.1 Lack of Details in Title\nThe title for the overview chart is ‘Population Structure in 9 planning areas in SG(June 2022)’, which in itself provides details on location, time and data. However, there is an omission of context on why those planning areas are selected in the overview graph title. The term ‘population structure’ is a vague description, mentioning age-sex pyramid would have been more prudent. The same issue is echoed for the detailed chart.\n\n\n2.1.2 Missing Data Source\nThe dashboard does not link the data source reducing the credibility of the dashboard figures.\n\n\n2.1.3 Varied Axes in the Detailed Chart\nFor the detailed chart, the author has displayed nine different age-sex pyramid charts put together in the dashboard, as opposed to using one chart showcasing all the chosen nine planning areas. This is an issue because the axes for all these planning areas are not uniform. For instance, when we zoom into ‘Novena’ and ‘Changi’ in the ‘Detailed population structure in Each Area’, we observe that the female population aged 90 and above appear to have a similar population count. However, when we hover over those points, it reveals that the population count in ‘Changi’ is 10 whereas it 310 for ‘Novena.’\n\n\n2.1.4 Too many groups in Age Group\nThe age bands for the grouping is 5 years which results in nineteen different groups. This is a lot of information for the brain to process together, the chart would be more readable if the age groups were reduced."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aesthetics",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aesthetics",
    "title": "Age-Population Pyramid - Singapore 2022 (RStudio)",
    "section": "2.2 Aesthetics",
    "text": "2.2 Aesthetics\n\n2.2.1 Loss of Space using Redundant Overview chart\nThe overview chart is conveying the same information as the detailed chart, with uniform axes for all nine planning areas, however it is displayed side by side as opposed to the 3X3 panel structure in the detailed chart. The panel area allocated to the overview chart is small, making it challenging for the audience to view and grasp information. For instance, look at ‘Changi’ in planning area, one can barely see the bars. The overview chart occupies space that could have been better used for the detailed chart, rendering it redundant.\n\n\n2.2.2 Unnecessary legend, filter and slide option\nThe axes are clearly labelled for ‘male population’ and ‘female population’ therefore there is no need for the legend as it wastes space. Additionally, the filter is for the overview chart, adding more planning areas would reduce the already hampered visibility of the overview chart, therefore its an unnecessary addition. The slider has no functionality in this chart and should be removed.\n\n\n2.2.3 Overlapping & Incomplete labels an in Overview Chart\nThe age group axis has age groups that are overlapping, thereby impeding graph readability. Additionally, the ‘female population’ axis label is not appearing completely in view, which makes the graph look untidy.\n\n\n2.2.4 Missing Age Group Axis label\n‘Age’ as a label has been mentioned only in ‘Ang Mo Kio’. The label has a small font, which can be overlooked by the audience. While, the audience is smart enough to gauge that the groups on the Y axis is ‘Age Groups’, it would be better to add it in as it makes the graph look more complete.\n\n\n2.2.5 Incorrect Layout for the Dashboard View\nThe dashboard layout is not set to ‘Automatic’, therefore even in ‘Full View’ option in ‘Tableau Public’, one needs to scroll, which is a hassle for the viewer. The audience can better understand the graph if it appears in the same window."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/In-Class_Ex03.html",
    "href": "In-Class_Ex/In-Class_Ex03/In-Class_Ex03.html",
    "title": "In-Class_Ex03",
    "section": "",
    "text": "pacman::p_load(ggiraph, tidyverse)\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "title": "Interactivity",
    "section": "",
    "text": "Importing exam data for performing visualisation\n\nexam_data <- read.csv(\"data/Exam_data.csv\")\n\nWorking with visual variable: plot_ly() method. One can hover over the points to see the coordinates, play around with the legend - to highlight one or more and one can zoom in and out.\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\nCreating an interactive plot using ggplotly:\n\np <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER,\n  y = MATHS,\n  type = \"p\",\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = ENGLISH,\n  y = MATHS,\n  marginal = FALSE)\n\n\n\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\n\nWe want to estimate the price of the car\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\ngtsummary will take my regression model and save it in a data table form. More in https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html\n\nmodel %>% tbl_regression(intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,636,783\n-3,150,331, -2,123,236\n<0.001\n    Age_08_04\n-14\n-35, 7.1\n0.2\n    Mfg_Year\n1,315\n1,059, 1,571\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n19\n17, 21\n<0.001\n    Guarantee_Period\n28\n3.8, 52\n0.023\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nTo check for multicollinearity\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nView(check_c)\nmodel[[\"coefficients\"]]\n\n     (Intercept)        Age_08_04         Mfg_Year               KM \n   -2.636783e+06    -1.409333e+01     1.314938e+03    -2.323290e-02 \n          Weight Guarantee_Period \n    1.902743e+01     2.769708e+01 \n\n\nRunning model 1\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, data = car_resale)\n\nCheck_model to perform all checks. We can do this for linear model but cannot do it for bootstrap, etc.\n\ncheck_n <- check_normality(model1)\ncheck_h <- check_heteroskedasticity(model1)\n\ncheck_n\n\nWarning: Non-normality of residuals detected (p < .001).\n\ncheck_h\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\ncheck_model(model1)\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#visualising-the-uncertainty-of-point-estimates",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#visualising-the-uncertainty-of-point-estimates",
    "title": "Interactivity",
    "section": "Visualising the uncertainty of point estimates",
    "text": "Visualising the uncertainty of point estimates\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html",
    "title": "Ternary",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nThe code chunks below will accomplish the task.\n\npacman::p_load(ggtern, plotly, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#the-data",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#the-data",
    "title": "Ternary",
    "section": "The data",
    "text": "The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\nImporting Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#preparing-the-data",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#preparing-the-data",
    "title": "Ternary",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#plotting-a-static-ternary-diagram",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#plotting-a-static-ternary-diagram",
    "title": "Ternary",
    "section": "Plotting a static ternary diagram",
    "text": "Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nImproving the plot\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#plotting-an-interative-ternary-diagram",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Ternary.html#plotting-an-interative-ternary-diagram",
    "title": "Ternary",
    "section": "Plotting an interative ternary diagram",
    "text": "Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html",
    "title": "Heatmap",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#importing-the-data-set",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#importing-the-data-set",
    "title": "Heatmap",
    "section": "Importing the data set",
    "text": "Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#preparing-the-data",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#preparing-the-data",
    "title": "Heatmap",
    "section": "Preparing the data",
    "text": "Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) <- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#transforming-the-data-frame-into-a-matrix",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#transforming-the-data-frame-into-a-matrix",
    "title": "Heatmap",
    "section": "Transforming the data frame into a matrix",
    "text": "Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#heatmap-of-r-stats",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#heatmap-of-r-stats",
    "title": "Heatmap",
    "section": "heatmap() of R Stats",
    "text": "heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#working-with-heatmaply",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#working-with-heatmaply",
    "title": "Heatmap",
    "section": "Working with heatmaply",
    "text": "Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#data-trasformation",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#data-trasformation",
    "title": "Heatmap",
    "section": "Data trasformation",
    "text": "Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\n\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nPercentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#clustering-algorithm",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#clustering-algorithm",
    "title": "Heatmap",
    "section": "Clustering algorithm",
    "text": "Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#seriation",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#seriation",
    "title": "Heatmap",
    "section": "5.4 Seriation",
    "text": "5.4 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#working-with-colour-palettes",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#working-with-colour-palettes",
    "title": "Heatmap",
    "section": "Working with colour palettes",
    "text": "Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#the-finishing-touch",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Heatmap.html#the-finishing-touch",
    "title": "Heatmap",
    "section": "The finishing touch",
    "text": "The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html",
    "title": "Corrplot",
    "section": "",
    "text": "Before you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#importing-data",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#importing-data",
    "title": "Corrplot",
    "section": "Importing Data",
    "text": "Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#building-a-basic-correlation-matrix",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#building-a-basic-correlation-matrix",
    "title": "Corrplot",
    "section": "Building a basic correlation matrix",
    "text": "Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#the-basic-plot",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#the-basic-plot",
    "title": "Corrplot",
    "section": "The basic plot",
    "text": "The basic plot\nOne of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggcorrmat(\n  data = wine,\n  cor.vars = 1:11\n)\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#building-multiple-plots",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#building-multiple-plots",
    "title": "Corrplot",
    "section": "Building multiple plots",
    "text": "Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Corrplot",
    "section": "Visualising Correlation Matrix using corrplot Package",
    "text": "Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#getting-started-with-corrplot",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#getting-started-with-corrplot",
    "title": "Corrplot",
    "section": "Getting started with corrplot",
    "text": "Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#combining-corrgram-with-the-significant-test",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#combining-corrgram-with-the-significant-test",
    "title": "Corrplot",
    "section": "Combining corrgram with the significant test",
    "text": "Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables. We can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#reorder-a-corrgram",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05_Corrplot.html#reorder-a-corrgram",
    "title": "Corrplot",
    "section": "Reorder a corrgram",
    "text": "Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n\n\n\n\nStrong correlation between free sulfur dioxide and total sulfur dioxide"
  }
]